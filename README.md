# Smart-Blind-Stick-
Smart Blind Stick with camera and raspberry pi 

Aim
Abstract: Smart Blind Stick is a device designed to help guide the visually impaired by detecting objects and portray the information to them in the form of speech. This reduces the human effort and gives better understanding of the surrounding. Furthermore it also provides an opportunity for visually impaired people to move from one place to another without being assisted by others. The device can also be used in old age homes where old age people have difficulty in their day to day activities due to decreased vision. With this paper, the aim to aid people in need to “see” the surroundings. Since the field of artificial intelligence is doing great progress now and features like object detection is getting easier and computationally feasible, these
features are implemented in the paper. The paper focuses on object detection and classification on pictures which are captured by the device mounted on a stick whose information can then be relayed to the user in means of sound or speech.

 PROBLEM STATEMENT
 According to World Health Organization (WHO), there are over 1.3 billion people who are visually impaired across the globe [1], out of which more than 36 million people are blind. India being the second largest population in the world, contributes 30% of the overall blind population. Although there are enough campaigns being conducted to treat these people, it has been difficult to source all the requirements. It is the era of artificial intelligence and it has gained immense traction due to large amount of data and ease of computation [2]. Using artificial intelligence it is possible to make these people’s life much easier. The goal is to provide a “secondary sight” until they have enough resources required to treat them. People with untreatable blindness can use this to make their everyday tasks much easier and simpler. II.  INTRODUCTION The paper focuses on making a device which is portable and provides a “secondary vision”. The device consists of a Raspberry Pi, a Hi-Res Camera, an object detection algorithm (YOLO) and a text to speech unit (eSpeak).This unit can be mounted on a stick from where, it can capture images and process them. The device alerts the user if they come across any obstacles and give the description of what is in front of them. It can classify objects using directory of self-learned models.

Since computation on the raspberry pi is pretty good, the images captured by the camera can be locally processed. The insight gained from these self-learned models can generate what is present in the images. This information is then converted to text. Then the text-to-speech module can inform the user about their surroundings. Smart Blind Stick is capable of detecting 80 classes in real time. The steps involved to do so are, repeatedly capture the image from the
camera, pass these images through the classifier and the results obtained from this are then read from the text to speech engine. The time it takes for the object detection is 0.426 seconds on average. The text to speech may take time to relay the information to the user depending on the number of objects present in front of them. There’s an ultrasonic sensor which captures the distance of the nearest object and says it to the user along with the results from the object detection. To achieve this, the device has to have a smaller footprint yet high computation requirement. The device should be affordable as well. So, raspberry pi was chosen for the price to performance ratio and its small size. It is also opensource and has a huge community support since it works on GNU/Linux platform. Wide range of distributions can be found and there are many libraries and frameworks which ease the programming. There’s also a camera which can be interfaced with it very easily. Section 1 defines the problem the paper aims on solving and the motivation for the paper. Section 2 gives us an introduction of the paper and how to go forth to solve this problem with the paper briefly. Section 3 contains all the related work of devices which help the blind. Section 4 gives us the methodology of the paper i.e. how the device is made and the required frameworks and programs in detail. Section 5 contains the results of the paper and what the user is going to get out of this paper. Section 6 contains the conclusions that can be drawn from this paper and the steps that can be taken for future improvements to make it even better.

 

